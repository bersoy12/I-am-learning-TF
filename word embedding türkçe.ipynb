{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d31b639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef68de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a2407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\berka\\Downloads\\turkish_movie_sentiment_dataset.csv', sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85e9062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment = df.comment.replace('\\n','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dab3d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment = df.comment.replace('\\r','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95404986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                    83227\n",
       "unique                   82451\n",
       "top                           \n",
       "freq                       300\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comment.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71f661f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      object\n",
       "film_name    object\n",
       "point        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b419d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.point)):\n",
    "    df.point[i] = df.point[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6c487e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53ef87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['point'] = df['point'].astype('string') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d5a4bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment      string\n",
       "film_name    object\n",
       "point        string\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aec686a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"film_name\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2947b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.comment)):\n",
    "    df.comment[i].encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dcc6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e8848cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c22dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ccc26ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>point</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jean Reno denince zaten ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ekşın falan izlemek isti...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bu yapım hakkında öyle ç...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter... (sting -...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jean Reno..bu adam kusur...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83222</th>\n",
       "      <td>Böyle bi kadrodan, bçyle...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83223</th>\n",
       "      <td>yani bu kaar ii oyuncalr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83224</th>\n",
       "      <td>bugün dvd'sini alıp izle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83225</th>\n",
       "      <td>Klasik korku ve gerilim....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83226</th>\n",
       "      <td>Bence gereğinden fazla b...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83227 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment point\n",
       "0                            Jean Reno denince zaten ...     5\n",
       "1                            Ekşın falan izlemek isti...     5\n",
       "2                            Bu yapım hakkında öyle ç...     5\n",
       "3                            finali yeter... (sting -...     5\n",
       "4                            Jean Reno..bu adam kusur...     5\n",
       "...                                                  ...   ...\n",
       "83222                        Böyle bi kadrodan, bçyle...     2\n",
       "83223                        yani bu kaar ii oyuncalr...     2\n",
       "83224                        bugün dvd'sini alıp izle...     1\n",
       "83225                        Klasik korku ve gerilim....     4\n",
       "83226                        Bence gereğinden fazla b...     4\n",
       "\n",
       "[83227 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a6be705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(83227, 2), dtype=string, numpy=\n",
       "array([[b'                      Jean Reno denince zaten leon filmi gelir akla izlemeyen kalmam\\xc4\\xb1\\xc5\\x9ft\\xc4\\xb1r ama kald\\xc4\\xb1ysada ee ne duruyorsun hemen izle :)                    ',\n",
       "        b'5'],\n",
       "       [b'                      Ek\\xc5\\x9f\\xc4\\xb1n falan izlemek istiyorsan\\xc4\\xb1z e\\xc4\\x9fer bunu izlemeyiin dostlar\\xc4\\xb1m keza ilk sahne hari\\xc3\\xa7 ek\\xc5\\x9f\\xc4\\xb1n filmde yerini gittik\\xc3\\xa7e duygusall\\xc4\\xb1\\xc4\\x9fa b\\xc4\\xb1rak\\xc4\\xb1r.. Mathildan\\xc4\\xb1n Leonun evine geldi\\xc4\\x9finde a\\xc4\\x9flad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1 sahnede ben de a\\xc4\\x9flam\\xc4\\xb1\\xc5\\x9f olabilirim.. Tamam olabilirim de\\xc4\\x9fil a\\xc4\\x9flad\\xc4\\xb1m; ama sen de izle a\\xc4\\x9flars\\xc4\\xb1n dostooom. Etkileyici bir film, s\\xc4\\xb1km\\xc4\\xb1yor hi\\xc3\\xa7bir salise boyunca sizi.\" Ben art\\xc4\\xb1k b\\xc3\\xbcy\\xc3\\xbcd\\xc3\\xbcm Leon, ya\\xc5\\x9flan\\xc4\\xb1yorum. \"\" Hayat hep b\\xc3\\xb6yle zor mu, yoksa sadece \\xc3\\xa7ocukken mi? \"                    ',\n",
       "        b'5'],\n",
       "       [b'                      Bu yap\\xc4\\xb1m hakk\\xc4\\xb1nda \\xc3\\xb6yle \\xc3\\xa7ok \\xc5\\x9fey yazabilirim ki kitap olur. O y\\xc3\\xbczden k\\xc4\\xb1sa kesmem laz\\xc4\\xb1m. Bir kere a\\xc4\\x9flad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1m iki filmden birisidir(di\\xc4\\x9feri = ye\\xc5\\x9fil yol). \\xc4\\xb0zledi\\xc4\\x9fim en iyi film midir karar veremeyece\\xc4\\x9fim ama izledi\\xc4\\x9fim en sanatsal sahneleri bar\\xc4\\xb1nd\\xc4\\xb1ran Luc Besson harikas\\xc4\\xb1 oldu\\xc4\\x9fu kesindir. Oyunculardan s\\xc4\\xb1k\\xc3\\xa7a bahseldilmi\\xc5\\x9f, o konuya girmeyece\\xc4\\x9fim ama Luc Besson abi sen de ne cevher varm\\xc4\\xb1\\xc5\\x9f demekten kendimi alam\\xc4\\xb1yorum. Y\\xc3\\xb6netmenlikten \\xc3\\xa7abuk \\xc3\\xa7ekilerek k\\xc4\\xb1yt\\xc4\\xb1r\\xc4\\xb1k aksiyon filmlerine senaryo yazman \\xc3\\xa7ok yaz\\xc4\\xb1k oldu ger\\xc3\\xa7ekten. T\\xc3\\xbcm bu \\xc3\\xb6vg\\xc3\\xbclerim Eric Serra i\\xc3\\xa7inde ge\\xc3\\xa7erlidir. Nitekim hi\\xc3\\xa7 abartm\\xc4\\xb1yorum; filmin % 50 si Eric Serra n\\xc4\\xb1n hakk\\xc4\\xb1d\\xc4\\xb1r. Muhte\\xc5\\x9fem melodilerine hayran\\xc4\\xb1m. Son olarak Natalie Portman a de\\xc4\\x9fineyim. Sen ne kadar tatl\\xc4\\xb1, munis bir \\xc5\\x9feymi\\xc5\\x9fsin yahu. K\\xc3\\xbc\\xc3\\xa7\\xc3\\xbckken ayr\\xc4\\xb1 bir havan \\xc5\\x9fimdi ayr\\xc4\\xb1 bir havan var. Az yazal\\xc4\\xb1m dedik ama d\\xc3\\xb6kt\\xc3\\xbcrm\\xc3\\xbc\\xc5\\x9f\\xc3\\xbcm g\\xc3\\xb6r\\xc3\\xbcyorumki... buradan da anlayabilirsiniz hayat\\xc4\\xb1m\\xc4\\xb1n filmi oldu\\xc4\\x9funu.                    ',\n",
       "        b'5'],\n",
       "       ...,\n",
       "       [b\"                      bug\\xc3\\xbcn dvd'sini al\\xc4\\xb1p izledim ama inan\\xc4\\xb1lmaz k\\xc3\\xb6t\\xc3\\xbc bir korku! bende iyi bir korku filmi sand\\xc4\\xb1m! biraz ge\\xc3\\xa7 izledim ama ke\\xc5\\x9fke param\\xc4\\xb1 vermeseydim...                    \",\n",
       "        b'1'],\n",
       "       [b'                      Klasik korku ve gerilim...                    ',\n",
       "        b'4'],\n",
       "       [b\"                      Bence gere\\xc4\\x9finden fazla bir ele\\xc5\\x9ftiri ald\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1n\\xc4\\xb1 d\\xc3\\xbc\\xc5\\x9f\\xc3\\xbcn\\xc3\\xbcyorum (k\\xc3\\xb6t\\xc3\\xbc anlamda) Film de bazi yerlerde kopukluk hissediliyor ama ben kendi ad\\xc4\\xb1ma 2 s 45 dk l\\xc4\\xb1k bir film bu kadar ak\\xc4\\xb1c\\xc4\\xb1 gitmemi\\xc5\\x9fti. Tarantino'nun en k\\xc3\\xb6t\\xc3\\xbc filmiymi\\xc5\\x9f yok art\\xc4\\xb1k pes! Daha iyi filmleri var tabii ki ama \\xc3\\xa7ok k\\xc3\\xb6t\\xc3\\xbc bir film de\\xc4\\x9fil. (Sanat y\\xc3\\xb6netmenini ayr\\xc4\\xb1 bir tebrik ediyorum)                    \",\n",
       "        b'4']], dtype=object)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9aefeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = df.sample(n=60000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4860045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df.comment, df.point, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "57a9d134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 2), dtype=string, numpy=\n",
       "array([[b'                      ben bu kadar g\\xc3\\xbczel bir film ne zamand\\xc4\\xb1r seyretmiyodum filmde a\\xc4\\x9flad\\xc4\\xb1m ya :D ger\\xc3\\xa7ekten bence s\\xc3\\xbcper film                    ',\n",
       "        b'5'],\n",
       "       [b'                      En yak\\xc4\\xb1n dostumun \"E\\xc5\\x9f\\xc5\\x9fek kadar adam oldunuz hala bu filmleri mi seyrediosunuz\" \\xc5\\x9feklindeki yorumuna sert bir dille cevap verdi\\xc4\\x9fim film:)Klasik amerikan gen\\xc3\\xa7li\\xc4\\x9fi filmi de olsa ya\\xc5\\x9fataca\\xc4\\x9f\\xc4\\xb1 e\\xc4\\x9flenceli dakikalar i\\xc3\\xa7in bile izlenir. 10/7                    ',\n",
       "        b'4'],\n",
       "       [b\"                      son zamanlarda seyretti\\xc4\\x9fim en k\\xc3\\xb6t\\xc3\\xbc film ata'n\\xc4\\xb1n ismi i\\xc3\\xa7in gittim filme ancak sonu\\xc3\\xa7 h\\xc3\\xbcsran\\xc5\\x9febnem han\\xc4\\xb1m'da kurtaramam\\xc4\\xb1\\xc5\\x9f filmi                    \",\n",
       "        b'0'],\n",
       "       ...,\n",
       "       [b'                      Sava\\xc5\\x9f filmlerini severim. Atmosferi bu kadar iyi yans\\xc4\\xb1tan \\xc3\\xa7ok az film g\\xc3\\xb6rd\\xc3\\xbcm. Bu da onlardan biri. T\\xc3\\xbcr\\xc3\\xbcn hayranlar\\xc4\\xb1 ka\\xc3\\xa7\\xc4\\xb1rmas\\xc4\\xb1n.                    ',\n",
       "        b'4'],\n",
       "       [b'                      Sinemada izledi\\xc4\\x9fime pi\\xc5\\x9fman oldu\\xc4\\x9fum filmlerden. Tamamen vakit kayb\\xc4\\xb1.                    ',\n",
       "        b'1'],\n",
       "       [b'                      Bir polisiye film i\\xc3\\xa7in \\xc3\\xa7ok yava\\xc5\\x9f ilerliyor.Cem Y\\xc4\\xb1lmaz bu filmde bile g\\xc3\\xbcld\\xc3\\xbcrmeyi ba\\xc5\\x9fard\\xc4\\xb1, \\xc5\\x9eener \\xc5\\x9eenin oyunculu\\xc4\\x9fu hat\\xc4\\xb1r\\xc4\\xb1na 10/7.                    ',\n",
       "        b'3']], dtype=object)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bb2d80f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [75]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      4\u001b[0m vectorize_layer \u001b[38;5;241m=\u001b[39m TextVectorization(\n\u001b[0;32m      5\u001b[0m     standardize\u001b[38;5;241m=\u001b[39mcustom_standardization,\n\u001b[0;32m      6\u001b[0m     max_tokens\u001b[38;5;241m=\u001b[39mvocab_size,\n\u001b[0;32m      7\u001b[0m     output_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m     output_sequence_length\u001b[38;5;241m=\u001b[39msequence_length)\n\u001b[1;32m---> 10\u001b[0m text_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x)\n\u001b[0;32m     11\u001b[0m vectorize_layer\u001b[38;5;241m.\u001b[39madapt(text_ds)\n",
      "File \u001b[1;32mc:\\users\\berka\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\generic.py:5583\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5577\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5579\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5581\u001b[0m ):\n\u001b[0;32m   5582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5583\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length)\n",
    "\n",
    "text_ds = train_ds.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4238e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
